# 基于 CNN 的高频交易噪声过滤与多空信号识别

任凯（2024 FinTech，2401212437）

```python
JS-Real-Time-Market-Data-Forecasting/
├── Data/ # Data directory, too big to upload.
    ├── train.parquet/ # Download raw data to this directory
    └── dataset/ # Run the code in `data_preprocess/` to get the dataset.
├── Code/ # Code directory
    ├── data_preprocess/ # Code for data prprocessing.
        ├── main.py # The pipline.
        └── utils.py # The utils functions.
 ├── datasets/ # The dataset.
     └── jsmp_dataset.py # Dataset module.
└── partition_id=9
```

## 1. Introduction

本作业以 Kaggle 竞赛 Jane Street 数据为例，展示 CNN 在时序数据处理中的特征提取与降噪方法，理解高频交易数据的特性与挑战。作业的核心目的是为了培养金融工程的系统性思维，帮助同学们建立从数据清洗、特征工程到模型构建与训练的完整量化研究流程，初步具备构建金融智能策略系统的能力。

本报告尽可能详细展示了作者解答本作业问题的思路，整体的组织架构直接参照助教给出的报告要求。总的来说，本作业解答核心框架如图 1. 所示，共分为**数据集处理、模型搭建和实验三个部分**。具体来看：数据集处理包括从竞赛官网下载原始数据、按照要求进行数据预处理以及重新组织数据三个关键步骤；模型搭建核心在于构造目标数据集、按要求构建模型以及设定合理的超参数集合；在上述两个部分完成后就可以开始进行实验，在训练和验证中调整模型架构和关键超参，进而得到并分析相关实验结果。

<img src="./Imgs/1-Framework.png" alt="Framework" style="zoom:50%;" />

<center>图 1. 作业整体框架</center>

需要进一步说明的是，本作业并没有如标准的神经网络项目那样，在训练、验证结束后在测试集上进一步测试，这核心是因为赛事主办方没有公开合理正确的测试集，尽管原是数据下载后有 `test` 的部分数据，但是这些数据的组织形式明显是过于模糊、简单化的。因此将本作业的重心放在对量化研究整体流程的理解上，首先通过将主办方提供的训练数据人工划分为训练和验证部分，然后拉通整体流程，最后对结果进行详细分析，在实现作业要求的同时，深刻地理解了各步骤中的处理细节，加深对数据处理、模型构建以及实验的认知。总而言之，本作业想要突出的核心工作如下：

- 本作业搭建了一套将高频交易时序数据转化为“类图像”数据，并基于 CNN 进行信号预测与噪音识别的通用项目框架。所有代码目前均已[**开源**](https://github.com/KarryRen/Karry-Studies-AI/tree/main/Cases/JS-Real-Time-Market-Data-Forecasting)。
- 数据处理上：基于对空缺值的探索，筛选关键指标并完成空值填充。进一步地使用 z-score 方法进行特征标准化，最终通过跨时间步和调整形状的方式将时序特征数据调整为通道数为滞后期 `time_step`，大小为 `(h, w)` 的"类图像"的三位张量数据。对于预测标签而言，首先保留了竞赛中衡量评分的关键标签 `responder_6`，其次根据偏离程度搭建了噪声识别标签 `is_noise`。
- 模型构造上：搭建的 Multi-CNN 模型，一方面在识别尺度上具有 “Multi” 特性，既有小尺度卷积操作也有较大尺度的卷积操作；另一方面在预测目标上具有 “Multi” 特性，既能输出对连续性标签 `responder_6` 的预测，又能输出对



## 2. Dataset

### 2.1 Data Description

本作业数据集来自 Kaggle 上 Jane Street 发起的一个[**竞赛**](https://www.kaggle.com/competitions/jane-street-real-time-market-data-forecasting/overview)。此数据库核心是匿名处理的真实交易数据，但由于比赛限制我们无法拿到合理的 test 数据针对真实情况进行调优，因此本作业解答专注在对 train 数据集上的研究，不调用主办方提供的测试数据和接口，以实现更加完整、流畅的练习目的，并呈现相对清晰、泛化的解题思路和框架。在此我对训练数据 `train.parquet` 进行了如下详细描述。

首先，在竞赛主页上完成**原始数据**下载后，训练数据的路径结构如下，由于整体数据量过大，所以将其分成十个部分（`id` 从 0 到 9），并以 `parquet` 的文件类型进行存储，**总内存约占 12.3 GB**。考虑到原始数据量过大，后续处理过于耗时，本项目只使用了 `id` 从 0 到 3 的 4 组数据，其中共包含 680 日下的 11,802,114 条交易数据，共出现 29 种交易标的。

```python
train.parquet/
├── partition_id=0
    └── part-0.parquet
├── partition_id=1
    └── part-1.parquet
├── ...
└── partition_id=9
    └── part-9.parquet
```

其次，读取数据并结合官方描述，可以得到对**数据字段**更详细的说明。共有 92 个字段，可分为如下 4 类：

- 标识性字段（3 个）
  - `date_id` 和 `time_id`： 按顺序排序的整数值，为数据提供时间顺序结构，尽管 `time_id` 值之间的实际时间间隔可能有所不同
  - `symbol_id`：匿名化的标的代码，唯一标识
- 权重字段（1 个）
  - `weight`：用于计算评分函数的权重
- 特征字段（79 个）
  - `feature_00` 到 `feature_78`：共 79 个匿名市场特征数据
- 响应字段（9 个）
  - `responder_0` 到 `responder_8`：共 9 个匿名响应者，介于 -5 和 5 之间。`responder_6` 是预测目标。

总的来看，数据集中的每一行都对应一个标的（用标识 `symbol_id` 标识）和一个时间戳（用 `date_id`和 `time_id` 标识）的唯一组合。`date_id` 列是一个整数，表示事件发生的日期，而 `time_id` 表示时间顺序。需要注意的是，它们之间的实际时间差异 `time_id` 不能保证一致。**注意**：`symbol_id` 字段实际是加密标识符，但 `symbol_id` 不保证每个标识符都会出现在所有 `time_id` 和 `date_id` 组合中。

### 2.2 Data Preprocess

原始数据存在众多问题，无法对其直接建模，需要进行多步骤的预处理。

**Step 1. 减少数据占存：筛选目标列，修改数据类型**

一方面，在响应字段中只保留预测目标 `responder_6`，这样数据总字段数变为 84 个。另一方面，对剩余的每个字段进行数据类型规范化，通过修改数据类型以减少大约 48.6% 的占存（从 3612.97 MB 到 1857.14 MB）。

**Step 2. 处理空缺值**

正如数据描述中的那样，不同日期下的 `symbol_id` 情况不同，一些标的会在某些日期中缺失。通过图 1. 可以发现，在 680 个交易日里，500 天前交易日中的 `symbol_id` 较比全局存在较多缺省，这对整体建模是十分不利的，因此选择直接剔除。剩余 180 个交易日下共 9,274,909 条交易数据。

紧接着需要对每个特征的空值进行检测，如表 1. 所呈现的对每一个建模特征和指标的描述性统计显示，大部分都存在空值，可以直接按照 `symbol_id` 分组前填充。填充前后各特征的空值情况如图 3. 所示。缺省值过多的直接删除，数据偏度太大也直接剔除。剩余的按照 Symbol 分组填中位数。

**Step 3. 数据归一化，与噪声识别构造**

进行全局 z-score 归一化。请注意：此处全局 z-score 只是对现实情形的模拟，现实中可以根据过往数据信息获得对全局均值方差的估计，但此处因为数据有限，所以只能用全局数据进行估计，这会导致未来信息泄漏，但是体现了核心思想，在此便不做更多讨论。

注意到，标准化后很多值存在较大偏差，此处根据标准差偏移量构造噪声识别标签，有任何一个特征偏差绝对值大于 4.5，就标记为噪音。此处标签是二分变量。

**Step 4. 结构化数据构建**

选择 `time_step = 3`，即同时看当前时间戳以及前两步的信息，同时进行数据结构化，得到最终的数据输入。按照时间先后进行训练和验证集的划分，前 160 天数据做训练集，后 20 天数据做验证集。



## 3. Methodology

### 3.1 Model Construction

按照给到的基础模型进行构造。

### 3.2 Train & Validation

搭建框架进行训练。



## 4. Experiment

调整参数，展示结果。





## References
